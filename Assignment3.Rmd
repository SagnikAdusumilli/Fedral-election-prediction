---
title: "Informative Title Name"
author: "GROUP NUMBER: ADD YOUR NAMES HERE"
date: November 5, 2021
subtitle: STA304 - Assignment 3
output:
  pdf_document: default
---

```{r, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(openintro)
library(tidyverse)
library(dplyr)
# should run the lines below if you don't have cesR package installed
# install.packages("devtools")
# devtools::install_github("hodgettsp/cesR")
library(nnet)
library(cesR)
library(caret)
library(Hmisc)
library(knitr)
library(magrittr)
library(expss)
library(labelled)
library(reshape2)  
library(stringr)
```

## Introduction

The Canadian Election Study is an annual survey of voting and other preferences and demographics which are thought to pertain to political behavior of Canadian voters.This survey is used to predict the overall popular vote of the next Canadian federal election (tentatively 2025) using a regression model with post-stratification.

Some of the important terminologies is the Majority government, which is the party that won the most number of votes and were elected to become the ruling government. Next, is the Minority party, it's the party with the least votes and they are elected to become the opposition to the majority party. Also, some of the parties mentioned below are Bloc Quebecois, Conservatives, Greens, Liberal, NDP, and People’s Party.

The research question we would be investigating is that does age, religion and location enough to predict the number of votes for each party?

In this paper we will use post-stratification and multilevel regression to investigate if certain features of the population population such as: age, religion, sex, household size and province can be used to predict how many votes each party gets in a federal election


## Data

### Data Collection Process
The Data is a collection of two datasets. The first dataset contains data from the General Social Survey on Family (cycle 31) on 2017. Canada's General Social Survey (GSS) program conducts annual survey covering one topic in depth (citation). As such, this dataset contains mostly contains information pertaining to families. However, we will later investigate some common variables between this dataset and the Canada Election Study (CES) dataset. This will give us a list of factors in the general population that could be potentially associated to political affiliations

the Canada Election Study (CES) data which was collected in 2019. This data was collected from a questionnaire delivered to the people living in Canada through the Computer Assisted Telephone Interviewing(CATI). Phone calls were made potential interviewees during both the day and evening for every weekday. These questions asked some personal information such as their age and also political opinions such as "what is your opinion on Justin Trudeau?" (citation)

```{r, include = FALSE}
# loading the data
gss_data <- read.csv('./gss_clean.csv')
get_ces("ces2019_phone") # we are getting 2019 phone survey data
# no warning from this line #4021 obs of 278 variables.
# coverts categorical variable factors acutomatically 
survey_data <- labelled::to_factor(ces2019_phone) 

```

### Data cleaning
```{r, include = FALSE}

# find common topics between both the datasets
ces_labelNames <- label(survey_data)
gss_colNames <- colnames(gss_data)

ces_strings <- str_split(ces_labelNames, ' ')
gss_strings <- str_split(gss_colNames, '_')

# get common words for each col
common_words <- intersect(unlist(gss_strings), unlist(ces_strings))
common_words <- c(common_words, c("age"))

# which labels contain the important words. look at the dictionary
ces_label_dict <- data.frame(colName = colnames(survey_data), labelName = label(survey_data))

survey_data_clean <- survey_data
sum(is.na(survey_data$age))

#gender cleaning
survey_data_clean <- survey_data %>% 
  filter(q3 == '(1) Male' | q3 == '(2) Female') %>%
  mutate(sex = if_else(q3 == '(1) Male', 'Male', 'Female')) %>%
  select(-q3)

#q4 province
survey_data_clean <- survey_data_clean %>% dplyr::rename(province = q4)
sum(is.na(survey_data_clean$province))

#q63 religion_imporatance
survey_data_clean$q63 <- str_sub(survey_data_clean$q63, 5)
survey_data_clean <- survey_data_clean %>%
  dplyr::rename(religion_importance = q63) %>%
  filter(!is.na(religion_importance) & religion_importance != " Refused") %>%
  mutate(religion_importance = trimws(religion_importance, 'l'))

gss_data_clean <- gss_data %>% 
  dplyr::rename(religion_importance = regilion_importance) %>%
  filter(!is.na(religion_importance))


sum(is.na(survey_data_clean$q65)) #2166 out of 2576 NA, we will not use this variable
nrow(survey_data_clean)

#aboriginal
survey_data_clean <- survey_data_clean %>%
  dplyr::rename(aboriginal = q66a_15) %>%
  filter(aboriginal == '(1) Selected' | aboriginal == '(0) Not Selected') %>%
  mutate(aboriginal = if_else(aboriginal == '(1) Selected', 'Yes', 'No'))
#there are few data points saying "Don't know", so it was not worth recording

gss_data_clean <- gss_data_clean %>% filter(aboriginal == 'Yes' | aboriginal == 'No')

#employment status 91% of this is NA, other col main_activity 
#is also NA without clean-up at the gss_cleaning.R this info is not usable

#occupation there are no common occupation that has a string match skip for now

#education level 
survey_data_clean <- survey_data_clean %>%
  dplyr::rename(education = q61)

survey_data_clean <- survey_data_clean %>%
  filter(education != "(-8) Refused" & education != "(-9) Don't know") %>%
  mutate(education = case_when(
    education == "(9) Bachelor's degree" ~ "Bachelor",
    education == "(10) Master's degree" ~ "Above Bachelor",
    education == "(11) Professional degree or doctorate" ~ "Above Bachelor",
    TRUE ~ "Below Bachelor"
  ))

# map each category from gss to a category
# "High school diploma or a high school equivalency certificate" "Trade certificate or diploma"                                
# "Bachelor's degree (e.g. B.A., B.Sc., LL.B.)"                  "College, CEGEP or other non-university certificate or di..." 
# "Less than high school diploma or its equivalent"              "University certificate or diploma below the bachelor's level"
# "University certificate, diploma or degree above the bach..."

gss_data_clean <- gss_data_clean %>%
  filter(!is.na(education)) %>%
  mutate(education = case_when(
    education == "Bachelor's degree (e.g. B.A., B.Sc., LL.B.)" ~ "Bachelor",
    education == "University certificate, diploma or degree above the bach..." ~ "Above Bachelor",
    TRUE ~ "Below Bachelor",
  ))

#hh_size
survey_data_clean$q71<- as.numeric(as.character(survey_data_clean$q71))
survey_data_clean <- survey_data_clean %>%
  filter(!is.na(q71)) %>%
  dplyr::rename(hh_size = q71)

common_cols <- intersect(colnames(survey_data_clean), colnames(gss_data_clean))

gss_common_data <- gss_data_clean[, common_cols]
survey_common_data <- survey_data_clean[, common_cols]

# add vote variable for survey_data
survey_common_data$vote <- survey_data_clean$vote
survey_common_data <- survey_common_data %>%
  mutate(vote = case_when(
    vote == "(1) Liberal (Grits)" ~ 'Liberal',
    vote == "(3) NDP (New Democratic Party, New Democrats, NDPers)" ~ 'NDP',
    vote == "(2) Conservatives (Tory, PCs, Conservative Party of Canada)" ~ 'Conservatives',
    vote == "(5) Green Party (Greens)" ~ 'Greens',
    vote == "(6) People's Party" ~ "People's Party",
    vote == "(4) Bloc Québécois (BQ, PQ, Bloc, Parti Québécois)" ~ "Bloc Quebecois",
  ))

survey_common_data <- na.omit(survey_common_data)

survey_common_data$province = colsplit(survey_common_data$province," ", names = c("chuck","province"))[,2]
survey_common_data$religion_importance <- survey_common_data$religion_importance %>% str_replace_all("Not important at all", "Not at all important")
  
# write_csv(gss_common_data, "gss_common_data.csv")
# write_csv(survey_common_data, "survey_common_data.csv")
```

The regression model to be constructed, will be applied to both datasets, therefore only variables that appeared in both the datasets could be used. One way was examine if there were common terms present in the columns for both the dataset. Unfortunately most the columns the CES dataset were just question numbers. However, each column also had a label that stated the question itself. For example column "q2" had the label "In what year were you born?". Hence we collected common words that appeared in the columns of the GSS data and the labels of the CES data to find possible topics that were common in both datasets. 

Then for each topic we search the columns for both the dataset to see if any two column were describing identical or similar variables. These are the variables we found:

* Age: The age of the person was recorded in both data with the same column names.

* Sex: Gender was recorded in CES data and sex was recorded in the GSS data. Here we assumed the people who reported their gender to be male or female also would have the same sex as their gender. Hence we removed all genders that were not male or female and renamed the q3 column in the CES data to sex.

* Province: Both the datasets recorded the province a person lived in.

* religious importance: Both datasets recorded how the level of importance for religion. The categorical values in both the datasets were the same with the exception of an additional value "Refused" being present in the CES data. We removed rows containing this value from the CES data.

* Aboriginal: Both datasets recorded if a person was aboriginal or not. This was an option for question 66a in CES data which asked which ethnicity the person belonged to. q66a_15 recorded if the person belonged to an Aboriginal group. the value "(1) Selected" indicated the person identified as original and "(0) Not Selected". We filtered out other values as the indicated that the question was skipped or if the person was not sure. Then we mutated "(1) Selected" to "Yes" and "(0) Not Selected" to "No" to match the values of the variable in both dataset. Both datasets had values "Don't know" to indicate that a person was not sure. However, there very few rows with this value so we removed these rows.

* Education Level: Both datasets recorded the highest level of education completed by a person. However, these categories had slightly different names. For example, "University certificate, diploma or degree above the bach.." indicated that a person has a qualification above a bachelor's degree. In the CES data there are Master's degree as well as other degree above bachelor's degree. Hence we put the education level in both datasets into three groups: "Above Bachelor", "Below Bachelor" and "Bachelor".

* Household size: Both the datasets recorded household size.

After finding the common variables, we removed rows with missing values in these columns for both the datasets. Then we renamed the columns of the CES data to match the names of the columns of the GSS data. This was done so that models constructed on the CES data could also be used on the GSS data for post-stratification. Then we took the common variables and constructed two datasets. One dataset containing the rows from the CES data and the other dataset containing the rows of the GSS data. Futhermore, in the first dataset, voting data was added to the CES variables. This is the outcome of interest

```{r, echo=FALSE}
var_names <- colnames(survey_common_data)

var_description <- c(
  "Sex of the person",
  "Province that a person is currently residing in",
  "Level of education divided into three categories: 'Above Bachelor', 'Below Bachelor' and 'Bachelor'",
  "How important is their religion to a person: 'Not important at all', 'Somewhat important',   'Very important', 'Not very important'   'Don't know'",
  "Is the person aboriginal",
  "How many people does a person share their living space with including themselves",
  "Age of the person in years",
  "Party that the person will/might/has vote(d) for"
)

description_table <- data.frame(var_names, var_description)
kable(description_table, col.names = c('Variable Name', 'Description'), caption = 'Variable description table', padding = 20)
```

\newpage
### Numerical Summaries 


```{r, echo = FALSE}

# Use this to create some plots. Should probably describe both the sample and population.
survey_common_data <- remove_labels(survey_common_data)
survey_common_data <- droplevels(survey_common_data)
survey_common_data %>% 
  tab_cells("**Sex**" = sex, 
            "**Province**" = province, 
            "**Education**" = education,
            "**Religion Importance**" = religion_importance,
            "**Aboriginal**" = aboriginal,
            "**vote**" = vote
            ) %>% 
    tab_cols(total(label = "Count")) %>% 
    tab_stat_cases(total_row_position = "none") %>% 
    tab_pivot() %>% 
    split_columns() %>%
    kable(caption = "Frequency for each category in the CES data")
```
From the above table we can gain the following insights on the survey data:

* There seems to slightly more males and females in this dataset.

* Most of the people in the survey have an education level below a bachelor's degree.

* Most of the people in give a lot of importance or at least some importance to their religion.

* The large majority of the people in the survey are not Aboriginal. This perhaps suggests that this variable might not be of use for the model.

* It seems that the most popular party was the Conservative party followed closely by the Liberal party in 2019

* There does not seem to be an significant difference in the number of answered the survey for each province. This indicates that this survey represents the data of each province fairly well. 

\newpage
```{r, echo = FALSE}
gss_common_data %>% 
  tab_cells("**Sex**" = sex, 
            "**Province**" = province, 
            "**Education**" = education,
            "**Religion Importance**" = religion_importance,
            "**Aboriginal**" = aboriginal
            ) %>% 
    tab_cols(total(label = "Count")) %>% 
    tab_stat_cases(total_row_position = "none") %>% 
    tab_pivot() %>% 
    split_columns() %>%
    kable(caption = "Frequency for each category in the GSS data")
```
In the census data the differences observed in the categorical variables are similar to the differences observed in the survey data, with the exception of Sex. There are more females than males in the census data. This indicates that there is an underrepresentation of females in the data survey data.

\newpage
```{r, echo=FALSE}
means <- c(mean(gss_common_data$age), mean(survey_common_data$age))
mins <- c(min(gss_common_data$age), min(survey_common_data$age))
maxes <- c(max(gss_common_data$age), max(survey_common_data$age))
devs <- c(sd(gss_common_data$age), sd(survey_common_data$age))
d1 <- data.frame(means, mins, maxes, devs)
rownames(d1) <- c("From GSS dataset", "From CES Dataset")
kable(d1, 
      col.names = c("mean age", "minmum age", "maximum age", "standard deviation in years"),
      caption = c("Comparing Age variable in both dataset"), align = "c")
```
Even though the mean age is similar in both datasets, the magnitude of the min, max and standard deviation values indicates that age has a wider distribution in GSS dataset.

```{r, echo=FALSE}
medians_hh <- c(median(gss_common_data$hh_size), median(survey_common_data$hh_size))
mins_hh <- c(min(gss_common_data$hh_size), min(survey_common_data$hh_size))
maxes_hh <- c(max(gss_common_data$hh_size), max(survey_common_data$hh_size))
q1_hh <- c(quantile(gss_common_data$hh_size, 0.25), quantile(survey_common_data$hh_size, 0.25))
q2_hh <- c(quantile(gss_common_data$hh_size, 0.75), quantile(survey_common_data$hh_size, 0.75))
d2 <- data.frame(q1_hh, medians_hh, q2_hh, mins_hh, maxes_hh)
rownames(d2) <- c("From GSS dataset", "From CES Dataset")
kable(d2, 
      col.names = c("25th qauntile household size", "median household size", "75th quantile household size", 
                    "min household size", "max household size"),
      caption = c("Comparing Age variable in both dataset"), align = "c")
```
From this table, we can see that household size has similar distributions, however CES data seems to indicate that people in this dataset tend to have more household members. The max size 15 could be a potential outlier 

\newpage
### Graphical Summaries
```{r, echo=FALSE}
# 1 histogram of province and vote
ggplot(survey_common_data, aes(province, fill=vote))+
  geom_bar()+
  coord_flip()+
  scale_fill_brewer(palette="Dark2")+
  labs(title = 'Number of votes for each party per province',
       caption = 'Figure 1',
       y = 'Vote count', 
       x = 'Province')
```
From this table, it looks that the Liberal party is the most popular party in Ontario and all the provinces to its left. Manitoba and all the provinces on its right favor the Conservatives most. It is perhaps somewhat surprising that Bloc Quebecois are not the most popular party in Quebec as it is a party that is most focused on Quebec.

```{r, echo=FALSE}
# 1 histogram of province and vote
ggplot(survey_common_data, aes(education, fill=vote))+
  geom_bar()+
  coord_flip()+
  scale_fill_brewer(palette="Dark2")+
  labs(title = 'Number of votes for each party per Education Level',
       caption = 'Figure 2',
       y = 'Vote count', 
       x = 'Education Level')
```
From this plot we can see, that the ratio of votes for each party does not change much across education levels. This seems to suggest that political affiliation is independent of education. 

```{r, echo=FALSE}
# scatter plot for age vs vote
age_vote_aggr <- survey_common_data[, c("age", "vote")]%>% 
  group_by(age, vote) %>% 
  mutate(Count = n())

# ggplot(data = age_vote_aggr, aes(x = age, y = Count, color = vote))+
#    geom_point()
ggplot(survey_common_data, aes(age, fill=vote))+
  geom_histogram(bins = 1 + 3.322*log(nrow(survey_common_data)))+
  scale_fill_brewer(palette="Dark2")+
  labs(title = 'Number of votes of each party vs age',
       caption = 'Figure 3',
       y = 'Vote count', 
       x = 'Age')
```
From this table we can see the number of votes with respect to age, follows a roughly normal distribution. With most of the votes coming from people aged between 50 and 75. There is not clear ratio differences in vote ratio across the ages ages upto 75. However, the votes for parties other than Liberal or Conservatives decrease significantly for age groups older than 75.

```{r, echo=FALSE}
ggplot(survey_common_data, aes(religion_importance, fill=vote))+
  geom_bar()+
  coord_flip()+
  scale_fill_brewer(palette="Dark2")+
  labs(title = 'Number of votes for each party vs religiousness',
       caption = 'Figure 4',
       y = 'Vote count', 
       x = 'religiousness Level')
```
From this table, we again observe that the vote ratio between parties don't change across the groups. This suggests that political affiliation is independent of religion.

## Methods

The question that we are trying to answer is whether factors such as sex, province, age, education, religion importance, aboriginal and household size help us predict someone's voting preference. 


### Model Specifics

We will be using multinomial logistic regression to build our model as our dependent variable, or our response variable is a nominal variable. Multinomial logistic regression is an extension of binary logistic regression, but instead of two categories of the dependent variable it allows for multiple. Therefore it is suitable for our model as we are predicting which party will tend to have the overall popular vote of the next Canadian federal election (tentatively 2025). The formula can be written as follows:
Suppose our outcome of interest is $Y$ which has the levels $y_1, \ldots , y_j$ and we want to find predict $Y$ using the predictors $X_1, \ldots , X_k$. Then we can express the log odds of each level of Y as:

$$ log\left( \frac{P(y_i)}{1-P(y_i)} \right) = \beta_0+ \beta_1 X_1 +  \ldots +\beta_kX_k + \epsilon$$

where $log\left( \frac{P(y_i)}{1-P(y_i)} \right)$ is the log-odd of observing the outcome $y_i$. In this case $y_i$ outcome that the ith party gets the vote. $\beta_0$ represents the default value of the log-odds. The coefficient $B_l$ for $l \in \{ 1, 2, \ldots k\}$represent the change in log odds for one unit change in $X_l$ assuming that all other predictor values being constant. 
$\epsilon$ is a random variable that has a standard normal distribution. This term represents the error term in our prediction.

To get a prediction from this model we can do the following process: 
Let $\eta = \hat{\beta_0} + \hat{\beta_1}X_1 + \hat{\beta_2}X_2 + \ldots + \hat{\beta_k}X_k$.
Now we have that $log\left(  \frac{P(y_i)}{1-P(y_i)} \right) = \eta$.
Therefore we get that $P(y_i) = \frac{e^{\eta}}{1+ e^\eta}$.
we now have the probability of outcome $y_i$ from predictors. Now we can set a threshold $\gamma$ where if $P(y_i) \ge \gamma$ we predict 1 and 0 otherwise. Usually the $\gamma$ is set to 0.5 which means 50% probability

### Assumptions

* We assume choice of vote given to one party is not related to the choice of vote given to another party. This is know as assumption of independence among dependent variable choices 
* We also assume that we cannot perfectly separate all the cells by outcome groups. Each group would the party in this case
* We also assume that there is no natural ordering present between the party, meaning that we treat each party as equal. 

### Model construstion and testing
To get the estimates of each variable, we will be using the iterative maximum log likelihood estimation procedure (citation needed). For variable selection, one of the methods we will use  is backward selection using Akaike Information Criteria (AIC). The Akaike information criterion (AIC) is a mathematical method used for evaluating the best fit model. We use it by comparing multiple variables and their combination and select which combination is the best fit for the data. The AIC considers two things, the number of independent variables we used and the maximum likelihood estimate of the model. Therefore according to the AIC the best fit model would be one that considers the most variation and the least amount of variables. We have made use of the backward selection to select the right model. Backward selection works with all variables and keeps reducing one along the way to choose the best fit model. We have also took in consideration the accuracy of the model in our code, therefore choosing the model with the highest accuracy as well as lowest AIC.

Furthermore, we will also split the dataset into testing and training set and test the accuracy of each model on the testing set to further evaluate which model is more suitable
```{r include=FALSE}
# set reference level

set.seed(1000) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 75% of data as sample from total 'n' rows of the data 
droplevels(survey_common_data)
sample <- sample.int(n = nrow(survey_common_data), size = floor(.80*nrow(survey_common_data)), replace = F)
train <- survey_common_data[sample, ]
test  <- survey_common_data[-sample, ]

# Creating the Model
multinom_model <- multinom(vote ~ ., data = train)

# impleiment backward regression

vars <- colnames(train)
exclude_index <- 1
lowest_aic <- AIC(multinom_model)
best_model <- multinom_model
highest_acc <- 0
train_sub <- train
test_sub <- test
train
while(exclude_index < 7 && length(best_model) > 1) {
  if(which(names(train_sub)=="vote") == exclude_index){
    break
  }
  else {
  train_subset <- train_sub[, -(exclude_index)]
  test_subset <- test_sub[,  -(exclude_index)]
  mod <- multinom(vote ~ ., data = train_subset)
  aic <- AIC(mod)
  ClassPredicted <- predict(mod, newdata = test_subset, type = "class")
  # Building classification table
  tab <- table(test_subset$vote, ClassPredicted)
  

  # Calculating accuracy - sum of diagonal elements divided by total obs
  acc <- round((sum(diag(tab))/sum(tab))*100,2)
  
  if(aic < lowest_aic) {
    lowest_aic <- aic
    best_model <- mod
    train_sub <- train_subset
    test_sub <- test_subset
    }
  if(acc > highest_acc) {
    highest_acc <- acc
    best_model <- mod
    train_sub <- train_subset
    test_sub <- test_subset
    }
  else{
    exclude_index = exclude_index + 1
  }
  }
}
best_model

```


## Post-Stratification 
We will post stratification method in order to estimate the proportion of voters in each province.The reason post stratification is preferred is because stratified sample design increases the accuracy of estimates compared to a simple random sample especially for non-probability based sampling.
We partition the data into thousands of demographic cells, in the case of our study these cells are grouped by provinces and then we estimate response variable for each cell using a multilevel regression model. The sum of this cell levels estimates population-level estimate, $\hat{y}^{PS}$, by weighting each cell by its relative proportion in the population. The formula for this is:

$$ \hat{y}^{PS} = \sum N_j \hat{y}_j /  \sum N_j  $$
Where $\hat{y}_j$ is the estimate in each cell. And $N_j $ is the population size of the $J^{th}$ cell based off demographics. 

\newpage
## Results 
```{r include=FALSE}

broom::tidy(multinom_model)

test1 <- test
test2 <- test
# Predicting the values for train dataset
test1$ClassPredicted <- predict(best_model, newdata = test, type = "class")
test2$ClassPredicted <- predict(multinom_model, newdata = test, type = "class")
# Building classification table

tab1 <- table(test$vote, test1$ClassPredicted)
tab2 <- table(test$vote, test2$ClassPredicted)

# Calculating accuracy - sum of diagonal elements divided by total obs
acc_best <- round((sum(diag(tab1))/sum(tab))*100,2)
acc_full <- round((sum(diag(tab2))/sum(tab))*100,2)

```
The original multinomial logistic regression model (with all the variables) had an AIC of `r AIC(multinom_model)` but has a lower training accuracy than another model which had an AIC of `r AIC(best_model)`. However on the test set, the full model had an  test accuracy of `r acc_full` and the other model had an test accuracy of `r acc_best`. Hence we picked the original model as the final model.

```{r, echo=FALSE}
# have columns of coeffiecient for each table
model.table <- broom::tidy(multinom_model)
model.table <- model.table %>% rename(Party = y.level)
kable(model.table, caption = "Model output for each province")
```
Here the reference level is the party "Bloc Quebecois". This means that all coefficient estimates values are relative to this party. Consider the estimated coefficient of age for example. This can be interpreted the following: If all other variables are held constant then increasing age by one unit decreases the log-odds of the person voting for Conservative by 0.01697 relative to the log odds of them voting for "Bloc Quebecois". The standard error is the estimated deviance of this this estimate and the other statistic is the Z-score for the estimate. This is the z-score under then null hypothesis that the real coefficient value is 0. The p.value is the probability of deriving the observed estimated value under the null hypothesis. 

\newpage
We then performed our post-stratification where we first found the total number of individuals that voted for each party in each province. After, we took the party which had the most number of votes in each province to complete our post-stratification.
```{r echo=FALSE}

# Here I will perform the post-stratification calculation
gss_common_data$ClassPredicted <- predict(multinom_model, newdata = gss_common_data, type = "class")
gss_data_counts <- gss_common_data %>%
group_by(province, ClassPredicted) %>% 
mutate(count=n())
gss_popular_vote <- gss_data_counts %>%
  group_by(province) %>%
  select(province, ClassPredicted, count) %>%
  filter(count==max(count)) %>%
  distinct()

kable(gss_popular_vote, caption = "Post-Stratification Results showing Popular Vote by Province", col.names = c("Province", "Predicted Party", "Count"), align = "lcr")
```

The above table shows that among the ten provinces in the dataset, the Liberal Party is the most favored overall among individuals surveyed. The Liberal and Conservative Party are most favored in five provinces each. [https://www.datanovia.com/en/lessons/identify-and-remove-duplicate-data-in-r/]


```{r echo=FALSE}

library(ggplot2)

ggplot(data = gss_popular_vote, aes(x=province, y=count, fill=ClassPredicted))+geom_col() +
  labs(x="Province", y="Number of votes", caption = 'Figure 5')+
  ggtitle("Popular Vote by Province")+theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(axis.text.x = element_text(angle = 45, hjust=1))

```

The bar graph above shows that the Liberal Party was predicted to win by most individuals in Ontario, Quebec, Nova Scotia, Newfoundland, and Prince Edward Island. The Conservative Party had the popular vote in the remaining provinces. Ontario and Quebec are the two largest provinces in Canada and as seen in the graph have a much larger number people voting for the Liberal Party as compared to other Liberal and Conservative provinces. Hence, it makes sense that the Liberal party is predicted to win the election across all provinces in Canada. [https://www.biostars.org/p/464531/]

## Conclusions

Our aim was to analyze whether factors such as sex, province, age, education, religion importance, aboriginal, and household size help us predict an individual's voting preference. We expected an overall preference towards the Liberal Party among individuals since this was the majority party in Canada in 2019. We built a multinomial logistic regression model. We divided our data into training and testing tests to measure the accuracy of our model in order to accurately predict the voting trend of the public. We used the backward selection method and considered the to select the best model. 

We used post stratification method in order to estimate the proportion of voters in each province. We found that the Liberal Party was favored in five provinces and the Conservative party was favored in the other five. The Liberal Party was the most favored overall among all provinces in Canada.

A few weaknesses in our approach include:

* The AIC approach only provides a relative test of model quality. AIC would provide no indication if the statistical models used are equally a poor fit for the data [https://www.thoughtco.com/introduction-to-akaikes-information-criterion-1145956].

* When working with high dimensional datasets such as this one, there could be an over-fitting of the model on the training set. This may lead to inaccurate results in the model. We can use regularization techniques to avoid over-fitting, however, this will make the model much more complex [https://iq.opengenus.org/advantages-and-disadvantages-of-logistic-regression/].

* In the future, we can aim to conduct a post-stratification to estimate proportion of votes for other variables such as sex, education, or household size and analyze their voting preferences. This would help us broaden our analysis and draw up other conclusions on our dataset.


## Bibliography

1. Grolemund, G. (2014, July 16) *Introduction to R Markdown*. RStudio. [https://rmarkdown.rstudio.com/articles_intro.html](https://rmarkdown.rstudio.com/articles_intro.html). (Last Accessed: January 15, 2021) 

2. Dekking, F. M., et al. (2005) *A Modern Introduction to Probability and Statistics: Understanding why and how.* Springer Science & Business Media.

3.  Allaire, J.J., et. el. *References: Introduction to R Markdown*. RStudio. [https://rmarkdown.rstudio.com/docs/](https://rmarkdown.rstudio.com/docs/). (Last Accessed: January 15, 2021) 